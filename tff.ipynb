{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d3b798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.87.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_federated as tff\n",
    "tff.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7931b052-cd89-4cc9-afae-737697f8d9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.12\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7572adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from pycocotools.coco import COCO \n",
    "import os\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418b2ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the annotations file for COCO dataset\n",
    "# ANNOTATIONS_FILE = \"instances_val2017.json\"\n",
    "# ANNOTATIONS_URL = f\"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n",
    "# if not os.path.exists(ANNOTATIONS_FILE):\n",
    "#     urllib.request.urlretrieve(ANNOTATIONS_URL, \"coco_annotations.zip\")    !unzip -q coco_annotations.zip -d ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2b60ae95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.35s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Load COCO dataset annotations\n",
    "ANNOTATIONS_FILE = \"instances_val2017.json\"\n",
    "coco = COCO(f'annotations/{ANNOTATIONS_FILE}')\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_image(image_id):\n",
    "    image_info = coco.loadImgs(image_id)[0]\n",
    "    image_path = f\"http://images.cocodataset.org/val2017/{image_info['file_name']}\"\n",
    "\n",
    "    # Load and preprocess image\n",
    "    image = tf.io.decode_jpeg(tf.io.read_file(tf.keras.utils.get_file(image_info['file_name'], image_path)))\n",
    "    image = tf.image.resize(image, (128, 128))\n",
    "    image = image / 255.0\n",
    "\n",
    "    # Get label (just the first annotation category_id for simplicity)\n",
    "    ann_ids = coco.getAnnIds(imgIds=image_id)\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "    if not anns:\n",
    "        label = 0  # default/fallback class\n",
    "    else:\n",
    "        label = anns[0]['category_id']  # use first category_id\n",
    "\n",
    "    # Map COCO category_id (not consecutive) to a smaller range (0-9)\n",
    "    label = label % 10  # reduce to 10 classes just for demo\n",
    "    label = tf.one_hot(label, 10)  # one-hot encode\n",
    "\n",
    "    return image, label\n",
    "\n",
    "def make_client_data(image_ids):\n",
    "    data = [load_image(img_id) for img_id in image_ids]\n",
    "    images, labels = zip(*data)  # Unzip into separate lists\n",
    "    return tf.data.Dataset.from_tensor_slices((list(images), list(labels))).batch(1)\n",
    "\n",
    "\n",
    "federated_train_data = [make_client_data([img_id]) for img_id in image_ids]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eee6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')  # Assuming 10 classes\n",
    "    ])\n",
    "    return model\n",
    "# Convert to TFF model\n",
    "def model_fn():\n",
    "    keras_model = create_cnn_model()\n",
    "    return tff.learning.models.from_keras_model(\n",
    "        keras_model,\n",
    "        input_spec=federated_train_data[0].element_spec,\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.CategoricalAccuracy()]\n",
    "    )\n",
    "    return tff_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee928da8-1a1a-4e8e-b01a-79ab215e80a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'initialize'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m iterative_process = \u001b[43mtff\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearning\u001b[49m\u001b[43m.\u001b[49m\u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_weighted_fed_avg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_optimizer_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_optimizer_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Raymond/Desktop/federated/venv/lib/python3.11/site-packages/tensorflow_federated/python/learning/algorithms/fed_avg.py:250\u001b[39m, in \u001b[36mbuild_weighted_fed_avg\u001b[39m\u001b[34m(model_fn, client_optimizer_fn, server_optimizer_fn, client_weighting, model_distributor, model_aggregator, metrics_aggregator, loop_implementation)\u001b[39m\n\u001b[32m    240\u001b[39m   client_work = (\n\u001b[32m    241\u001b[39m       model_delta_client_work.build_functional_model_delta_client_work(\n\u001b[32m    242\u001b[39m           model=model_fn,\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m       )\n\u001b[32m    248\u001b[39m   )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m   client_work = \u001b[43mmodel_delta_client_work\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_model_delta_client_work\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_optimizer_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m      \u001b[49m\u001b[43mclient_weighting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_weighting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmetrics_aggregator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetrics_aggregator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m      \u001b[49m\u001b[43mloop_implementation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop_implementation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    257\u001b[39m finalizer = apply_optimizer_finalizer.build_apply_optimizer_finalizer(\n\u001b[32m    258\u001b[39m     server_optimizer_fn, model_weights_type\n\u001b[32m    259\u001b[39m )\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m composers.compose_learning_process(\n\u001b[32m    261\u001b[39m     initial_model_weights_fn,\n\u001b[32m    262\u001b[39m     model_distributor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    265\u001b[39m     finalizer,\n\u001b[32m    266\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Raymond/Desktop/federated/venv/lib/python3.11/site-packages/tensorflow_federated/python/learning/templates/model_delta_client_work.py:211\u001b[39m, in \u001b[36mbuild_model_delta_client_work\u001b[39m\u001b[34m(model_fn, optimizer, client_weighting, metrics_aggregator, loop_implementation)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;66;03m# We initialize the optimizer for the purposes of extracting its\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[38;5;66;03m# hyperparameters, using a \"whimsy\" spec.\u001b[39;00m\n\u001b[32m    210\u001b[39m whimsy_specs = tf.TensorSpec(shape=(), dtype=tf.float32)\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m whimsy_opt_state = \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43minitialize\u001b[49m(whimsy_specs)\n\u001b[32m    212\u001b[39m initial_hparams = optimizer.get_hparams(whimsy_opt_state)\n\u001b[32m    214\u001b[39m \u001b[38;5;129m@federated_computation\u001b[39m.federated_computation\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minit_fn\u001b[39m():\n",
      "\u001b[31mAttributeError\u001b[39m: 'function' object has no attribute 'initialize'"
     ]
    }
   ],
   "source": [
    "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(0.001),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(1.0)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f68683",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROUNDS = 5\n",
    "for round_num in range(1, NUM_ROUNDS + 1):\n",
    "    state, metrics = iterative_process.next(state, federated_train_data)\n",
    "    print(f'Round {round_num}, Metrics: {metrics}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b59c4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_model = create_cnn_model()\n",
    "state.model.assign_weights_to(evaluation_model)\n",
    "# Load new test images\n",
    "test_data = tf.data.Dataset.from_tensor_slices([load_image(img_id) for img_id in image_ids[5:10]]).batch(1)\n",
    "loss, accuracy = evaluation_model.evaluate(test_data)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
